# Configuration for DROID Point Cloud Generation

# Input paths
h5_path: "/data/droid/data/droid_raw/1.0.1/ILIAD/success/2023-06-11/Sun_Jun_11_15:52:37_2023/trajectory.h5"
extrinsics_json_path: "/data/droid/calib_and_annot/droid/cam2base_extrinsic_superset.json"
recordings_dir: "/data/droid/data/droid_raw/1.0.1/ILIAD/success/2023-06-11/Sun_Jun_11_15:52:37_2023/recordings/SVO"
metadata_path: null  # Auto-discover if null

# Output paths
rrd_output_path: "point_clouds/droid_full_fusion_gripper.rrd"
rrd_output_path_with_mask: "point_clouds/droid_full_fusion_gripper_with_mask.rrd"
video_output_path: "point_clouds/videos"

# Depth filtering parameters
wrist_max_depth: 0.75  # Meters (Close range for manipulation)
ext_max_depth: 1.5     # Meters (Wider context)
min_depth: 0.1         # Meters (Minimum valid depth for external cameras)
min_depth_wrist: 0.01  # Meters (Minimum depth for wrist cam rendering - includes gripper)
min_depth_wrist_icp: 0.15  # Meters (Minimum depth for ICP - excludes gripper at ~15cm)

# Visualization parameters
max_frames: 50         # Max frames to process
radii_size: 0.001      # Point size in meters
track_trail_length: 10 # How many past frames to keep line trails for gripper tracks

# ICP optimization parameters
icp_num_frames: 10     # Number of frames to sample for ICP optimization
icp_max_correspondence_distance: 0.05  # Max point correspondence distance (meters)
icp_voxel_size: 0.01   # Voxel size for downsampling (meters)

# Object detection parameters (for mask version)
debug_object_text: "Black Lid" # If set, skips VLM and uses this text for Grounding DINO
vlm_model: "gpt-5"
vlm_query_prompt: "What is the main object being manipulated? Answer in 2-3 words."
box_threshold: 0.35
text_threshold: 0.25
gdino_config: "/workspace/third_party/groundingdino-cu128/groundingdino/config/GroundingDINO_SwinT_OGC.py"
gdino_weights: "/workspace/third_party/groundingdino-cu128/weights/groundingdino_swint_ogc.pth"

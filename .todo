- [ ] Fix the 2D to 3D lifting 
- [ ] Lift hand tracking to 3D
- [ ] Lift Tracks to the rgb videos
- [ ] Select best 4 cameras with COLMAP, then use hand tracking to select relvant region, and complete depth for best view 
- [ ] segment the objects and track them (remove sam tracking)
- [ ] Finally settle for a good 2D/3D flow -> hae multiview alignment as this is one of the main selling points
- [x] enable hand tracking
- [ ] Finalize large scale code to train somerthing like flow..


- [x] Update the date for lab course
-  [ ] for grasping - data generation for side grasps? 

-  [x] Check if someone has the same camera as we and check then Intel Realsense d435i and d405
- add the robot and work with low res data
- all untouched by robot remains static for better colorization and grer to
add more points to the object modified and make it retain if on it gripper for contact flow
- [ ] Source gripper meshes per robot config and integrate: WSG-50 (ipa320/schunk_modular_robotics), Robotiq 2F-85 (ros-industrial/robotiq_85_description), DH Robotics AG-95 (vendor CAD/dh_gripper_ros). Update RH20T/models URDFs or load meshes alongside robot_pcd. Leave README note with download paths/licenses.
- remove the gripper and just track

- color clustrering 
- dbscan fÃ¼r gripper points
- remove the gripper along and keep the object points
- enable batch query

- write explainer of project with phd stud from zorah
- write MT Proposal

- if the ws code dev remote is not wrking over usb iphone disable dynamic forwarding

TODO: Apply a mask on the gripper 
Force the tracked points to be inside the gripper
Do the same for the objects
SOmehow make objects remain consistent
FIX COTRACKER AND MVTRACKER
-> maybe use the dense low resution stuff first